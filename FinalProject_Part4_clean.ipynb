{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project, Part 4: Technical Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Requirements:** Statistical analysis, model, evaluation metrics; don't forget: sample size, correlations, feature importance, unexplained variance or outliers, variable selection, train/test comparison, relationships between target and independent variables._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the many features available for us to explore, exploratory data analysis led us to narrow the features down to the **six** below. Including all the available features introduced too much collinearity and each unique feature combination became too small to easily calculate any sort of statistical significance.\n",
    "\n",
    "By narrowing down the number of features examined, we are definitely leaving out interesting influences like _datetime_, _detailed content relevance_, _user demographics_. Unfortunately, these more interesting investigations will need to be left for a future time. \n",
    "\n",
    "With the features below, we can still identify valuable takeaways as which creative sizes, _which platforms (desktop or mobile)_, _which sites_, and _where on the page_ an ad is mostly likely to generate a click. \n",
    "\n",
    "|Creative||User||Context|\n",
    "|------||------||------|\n",
    "|Creative Size||Device Category||Ad Unit 1 (domain)|\n",
    "|Line Item Type||||Ad Unit 3 (placement)|\n",
    "|Advertiser/Order|||||\n",
    "\n",
    "Of the six features above, we also discovered **collinearity**. Namely, **Ad Unit 1** and **Ad Unit 3** both have **Device Category** confounded within them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- number of rows\n",
    "- average ctr\n",
    "\n",
    "Interesting characteristics:\n",
    "- binary results, click or no click\n",
    "- feature conjunction (it's often a combination of two feature values that make a difference, like Advertiser vs Ad Unit 1. Behr paints ad works better next to Paint content.)\n",
    "- Categorical variables (Ad Unit 1 has X unique values, with no hierarchical order.) \n",
    "\n",
    "Binary results indicate **Logistic Regression** class of models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately for us, digital advertising is a lucrative __[$584 billion global business](http://www.dentsuaegisnetwork.com/media/dentsuaegisnetworknewsdetaila/2017/2017_06_15?Global-ad-spend-to-hit-5634-billion-in-2017-with-digital-driving-growth)__, so many smart people have already tried predicting CTR. \n",
    "\n",
    "#### __[\"Simple and scalable response prediction for display advertising\"](http://people.csail.mit.edu/romer/papers/TISTRespPredAds.pdf)__  (Chapelle, Manavoglu, Rosales; 2015)\n",
    "- **Methods:** Logistic Regression, Feature Hashing, Subsampling, L1 regularization\n",
    "- **Evaluation Metrics:** auROC\n",
    "\n",
    "#### __[\"Outbrain Click Prediction\"](http://cs229.stanford.edu/proj2016/report/JaiswalGopinathLimaye-OutbrainClickPrediction-report.pdf)__ (Limaye, Jaiswal, Gopinath; 2016)\n",
    "- **Methods:** One hot encoding, feature engineering for conjugate features, factorization machines, boosted trees model\n",
    "- **Evaluation Metrics:** MAP@12\n",
    "\n",
    "#### __[\"3 Idiots' Solution to 2014 Criteo Display Advertising Kaggle Challenge\"](https://www.kaggle.com/c/criteo-display-ad-challenge/discussion/10555)__\n",
    "- **Methods:** field-aware factorizatiom machines\n",
    "- **Evaluation Metrics:** MAP@12\n",
    "\n",
    "#### __[\"How Feature Engineering can help you do well in a Kaggle competition - Part I\"](https://medium.com/unstructured/how-feature-engineering-can-help-you-do-well-in-a-kaggle-competition-part-i-9cc9a883514d)__\n",
    "- **Methods:** One hot encoding, feature hashing, gradient boosted decision trees, logistic regression with Follow-the-Regularized-Leader (FTRL) optimizer, Field-aware Factorization Machines, Ensembling\n",
    "- **Evaluation Metrics:** MAP@12\n",
    "\n",
    "__[Other](https://www.slideshare.net/gabrielspmoreira/feature-engineering-getting-most-out-of-data-for-predictive-models)__ feature engineering options:\n",
    "- bin-counting\n",
    "- LabelCount encoding\n",
    "- Category embedding\n",
    "- Support Vector Machines (SVM) - new model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set evaluation metrics.\n",
    "1. Split train/test data set.\n",
    "2. Set baseline \"model\".\n",
    "3. One-hot encoding/feature hashing.\n",
    "4. Logistic regression w/ FTRL optimization.\n",
    "5. Try Field-aware Factorization Machines. \n",
    "6. Try Ensembling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several evaluation metrics that can be used with logistic regression models. (MSE, R^2 and other regression metrics _aren't_ appropriate for this categorical classification model.)\n",
    "\n",
    "- <font color=blue>**Confusion Matrix**: We care about correctly predicting clicks and care less about predicting non-clicks (they don't make us money). We'd also rather err on the side of conservation and let a click pass than to predict a click that doesn't happen; it is better to underpromise and overdeliver on a CTR estimate to a client.</font>\n",
    "\n",
    "- **Mean Average Precision (MAP)**: New evaluation metric we haven't explored in class that is derived from the confusion matrix. \n",
    "\n",
    "- **Receiver Operating Characteristic (ROC) curve**: Graph of a model's sensitivity (true positive rate) against its specificity (true negative rate). The more convex the curve is, the better.\n",
    "\n",
    "- <font color=blue> **Area Under Curve (AUC)**: \"Area under the ROC curve\" - a way of quantifying the ROC. A poor classifier has an AUC of 0.5; the best ones have an AUC as close to 1 as possible.</font>\n",
    "\n",
    "- **Log Loss**: Quantifies unpredictability of your model. The goal is to minimize this value.\n",
    "\n",
    "Since several Kaggle competitions have used **MAP@12**, I will use this evaluation metric as well. However, I plan on playing around with optimizing by Log Loss and AUC, too, if they somehow lead to a better model.\n",
    "\n",
    "<p><font color=blue>_**EDIT:** I couldn't find an easy-to-implement MAP metric in sklearn, so went with sklearn's standard accuracy score instead. Secondarily, I also looked at **re-call** and **precision** in the confusion matrix._</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Creating a list to store all the accuracy, AUROC and recall scores.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_score(model_name,accuracy,AUROC,recall):    \n",
    "    test_model = {\n",
    "        'model_name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'AUROC': AUROC,\n",
    "        'recall': recall\n",
    "    }\n",
    "    final_scores.append(test_model)\n",
    "    return final_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I proceed, just want to confirm we have enough data to use **three-way split**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../FinalProject_EDA_v2/final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,1:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4704 entries, 0 to 4703\n",
      "Data columns (total 15 columns):\n",
      "impressions         4704 non-null float64\n",
      "clicks              4704 non-null float64\n",
      "ad_unit_1           4704 non-null object\n",
      "ad_unit_3           4507 non-null object\n",
      "line_item_type      4704 non-null object\n",
      "order               4704 non-null object\n",
      "creative_size       4704 non-null object\n",
      "CTR                 4704 non-null float64\n",
      "null_ctr            4704 non-null float64\n",
      "ctr_diff            4704 non-null float64\n",
      "size_grouped        4704 non-null object\n",
      "device_category     4704 non-null object\n",
      "ad_unit_1_clean     4704 non-null object\n",
      "ad_unit_3_device    4507 non-null object\n",
      "ad_unit_1_order     4704 non-null object\n",
      "dtypes: float64(5), object(10)\n",
      "memory usage: 551.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235332097.0\n",
      "494645.0\n",
      "50028.0818452\n",
      "105.15412415\n"
     ]
    }
   ],
   "source": [
    "print df['impressions'].sum()\n",
    "print df['clicks'].sum()\n",
    "\n",
    "print df['impressions'].sum()/4704\n",
    "print df['clicks'].sum()/4704"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm… we average out to just 105 clicks per row. I'm not really sure how concerning this is. It seems like a very small number. I'll move forward in the meantime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940.8\n"
     ]
    }
   ],
   "source": [
    "print 4704*0.2 \n",
    "# how many rows will be in the test dataset if 80/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'impressions', u'clicks', u'ad_unit_1', u'ad_unit_3',\n",
       "       u'line_item_type', u'order', u'creative_size', u'CTR', u'null_ctr',\n",
       "       u'ctr_diff', u'size_grouped', u'device_category', u'ad_unit_1_clean',\n",
       "       u'ad_unit_3_device', u'ad_unit_1_order'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['line_item_type',\n",
    "                'ad_unit_1_order',\n",
    "                'size_grouped',\n",
    "                'ad_unit_3_device',\n",
    "                'device_category',\n",
    "                'ad_unit_1_clean'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feature_cols]\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I can run anything through models, need to convert my categorical variables into numerical ones. I'll try both One-Hot Encoding and Feature Hashing and see how performance compares.\n",
    "\n",
    "One-Hot is basically like get_dummies, so I'll just do that. __[(source)](https://stackoverflow.com/questions/36631163/pandas-get-dummies-vs-sklearns-onehotencoder-what-is-more-efficient)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['line_item_type',\n",
       " 'ad_unit_1_order',\n",
       " 'size_grouped',\n",
       " 'ad_unit_3_device',\n",
       " 'device_category',\n",
       " 'ad_unit_1_clean']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dummies.join(pd.get_dummies(df_dummies['line_item_type'],drop_first=True, prefix='line_item_type-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in feature_cols[1:]:\n",
    "    df_dummies = df_dummies.join(pd.get_dummies(df_dummies[col],drop_first=True, prefix=col+'-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(df_dummies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4704 entries, 0 to 4703\n",
      "Columns: 464 entries, impressions to ad_unit_1_clean-_The Spruce\n",
      "dtypes: float64(5), object(10), uint8(449)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_dummies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are 4704 rows and 464 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with CTR Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method bins CTR into just two binary categories, so we can use logistic regression per usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin CTRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Look at distribution, decide where to bin.\n",
    "2. Bin the CTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Decide where to set bin cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11cf08590>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUheDQ5LUxeCQJHUxOCRJXQwOSVKX/w/tSuTh/fyL/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cef4fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dummies['CTR'].plot(kind='hist', range=[0, 0.005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4704.000000\n",
       "mean        0.002104\n",
       "std         0.014702\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000198\n",
       "75%         0.001359\n",
       "max         0.500000\n",
       "Name: CTR, dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies['CTR'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because these CTRs are not weighted by impression volume, there are a lot of outliers. \n",
    "\n",
    "Removing all CTRs where impressions are <10,000 to see how that affects the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1343.000000\n",
       "mean        0.001609\n",
       "std         0.002772\n",
       "min         0.000000\n",
       "25%         0.000394\n",
       "50%         0.001031\n",
       "75%         0.002128\n",
       "max         0.081592\n",
       "Name: CTR, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies[(df_dummies['impressions'] > 10000)]['CTR'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11cc27b50>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFMpJREFUeJzt3X2wpnV93/H3xwXBBwoiJ3SzD1lMSCymutAjsdWkBGLk\nwbjYiRYnTajDZNMJTnXMNC6mE7VTZnBGg7EPNJtAXYwKiBookNYFSazTkXWB5VnqCmvZdWU3yGNM\nIMC3f9y/I7eba8+5z+5e5z57zvs1c8+5rt/1u677++Mc9+P1nKpCkqQ9vWjcBUiS5icDQpLUyYCQ\nJHUyICRJnQwISVInA0KS1MmAkCR1MiAkSZ0MCElSp0PGXcD+OOaYY2rVqlXjLkOSDiq33nrrX1XV\nxEz9DuqAWLVqFZs3bx53GZJ0UEnynVH6eYhJktTJgJAkdTIgJEmdDAhJUqfeAyLJkiS3J7muzR+X\n5JYkW5NcmeTFrf2wNr+1LV/Vd22SpL2biz2I9wL3Dc1/FLi4qn4KeBQ4r7WfBzza2i9u/SRJY9Jr\nQCRZDpwF/EmbD3AqcHXrsgE4u02vafO05ae1/pKkMeh7D+ITwO8Cz7f5VwKPVdWzbX47sKxNLwMe\nAmjLH2/9JUlj0FtAJHkrsKuqbj3A212bZHOSzbt37z6Qm5YkDenzTuo3Am9LciZwOPAPgD8Ejkpy\nSNtLWA7saP13ACuA7UkOAY4EHtlzo1W1HlgPMDk5Wfta3Kp11+/rqvtt20Vnje27JWlUve1BVNUF\nVbW8qlYB5wBfqapfA24GfrV1Oxe4pk1f2+Zpy79SVfscAJKk/TOO+yA+ALw/yVYG5xgube2XAq9s\n7e8H1o2hNklSMycP66uqvwD+ok0/AJzc0edvgXfMRT2SpJl5J7UkqZMBIUnqZEBIkjoZEJKkTgaE\nJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaE\nJKlTbwGR5PAkm5LckeSeJB9p7Z9K8mCSLe2zurUnySeTbE1yZ5KT+qpNkjSzPl85+jRwalU9leRQ\n4GtJ/rwt+3dVdfUe/c8Ajm+fnwMuaT8lSWPQ2x5EDTzVZg9tn5pmlTXA5W29rwNHJVnaV32SpOn1\neg4iyZIkW4BdwMaquqUturAdRro4yWGtbRnw0NDq21ubJGkMeg2IqnquqlYDy4GTk/wscAHwauD1\nwNHAB2azzSRrk2xOsnn37t0HvGZJ0sCcXMVUVY8BNwOnV9XOdhjpaeC/Aye3bjuAFUOrLW9te25r\nfVVNVtXkxMRE36VL0qLV51VME0mOatMvAd4MfHPqvEKSAGcDd7dVrgV+o13N9Abg8ara2Vd9kqTp\n9XkV01JgQ5IlDILoqqq6LslXkkwAAbYA/6b1vwE4E9gK/AB4d4+1SZJm0FtAVNWdwIkd7afupX8B\n5/dVjyRpdryTWpLUyYCQJHUyICRJnQwISVInA0KS1MmAkCR1MiAkSZ0MCElSJwNCktTJgJAkdTIg\nJEmdDAhJUicDQpLUyYCQJHUyICRJnQwISVInA0KS1KnPd1IfnmRTkjuS3JPkI639uCS3JNma5Mok\nL27th7X5rW35qr5qkyTNrM89iKeBU6vqdcBq4PQkbwA+ClxcVT8FPAqc1/qfBzza2i9u/SRJY9Jb\nQNTAU2320PYp4FTg6ta+ATi7Ta9p87TlpyVJX/VJkqbX6zmIJEuSbAF2ARuBbwOPVdWzrct2YFmb\nXgY8BNCWPw68ss/6JEl712tAVNVzVbUaWA6cDLx6f7eZZG2SzUk27969e79rlCR1m5OrmKrqMeBm\n4J8CRyU5pC1aDuxo0zuAFQBt+ZHAIx3bWl9Vk1U1OTEx0XvtkrRY9XkV00SSo9r0S4A3A/cxCIpf\nbd3OBa5p09e2edryr1RV9VWfJGl6h8zcZZ8tBTYkWcIgiK6qquuS3AtckeQ/ArcDl7b+lwKfTrIV\n+D5wTo+1SZJm0FtAVNWdwIkd7Q8wOB+xZ/vfAu/oqx5J0ux4J7UkqZMBIUnqZEBIkjoZEJKkTgaE\nJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqVOfj/vWXqxad/1YvnfbRWeN\n5XslHZzcg5AkdTIgJEmdDAhJUqc+30m9IsnNSe5Nck+S97b2DyfZkWRL+5w5tM4FSbYmuT/JW/qq\nTZI0s5FOUif5x1V11yy3/SzwO1V1W5IjgFuTbGzLLq6qj+3xHScweA/1a4AfB25M8tNV9dwsv1eS\ndACMugfxX5NsSvLbSY4cZYWq2llVt7XpJ4H7gGXTrLIGuKKqnq6qB4GtdLy7WpI0N0YKiKr6eeDX\ngBUM9gQ+m+TNo35JklXAicAtrek9Se5MclmSV7S2ZcBDQ6ttZ/pAkST1aORzEFX1LeDfAx8A/jnw\nySTfTPIvplsvycuBLwDvq6ongEuAnwRWAzuBj8+m4CRrk2xOsnn37t2zWVWSNAsjBUSS1ya5mMFh\nolOBX6mqf9SmL55mvUMZhMNnquqLAFX1cFU9V1XPA3/MC4eRdjDYQ5myvLX9iKpaX1WTVTU5MTEx\nSvmSpH0w6h7EfwJuA15XVecPnVv4LoO9ir8nSYBLgfuq6g+G2pcOdXs7cHebvhY4J8lhSY4Djgc2\nzWYwkqQDZ9RHbZwF/M3UFUVJXgQcXlU/qKpP72WdNwK/DtyVZEtr+yDwriSrgQK2Ab8FUFX3JLkK\nuJfBFVDnewWTJI3PqAFxI/BLwFNt/qXAl4F/trcVquprQDoW3TDNOhcCF45YkySpR6MeYjq8qqbC\ngTb90n5KkiTNB6MGxF8nOWlqJsk/Af6mn5IkSfPBqIeY3gd8Psl3GRw2+ofAv+ytKknS2I0UEFX1\njSSvBn6mNd1fVX/XX1mSpHGbzQuDXg+sauuclISquryXqiRJYzfqw/o+zeDu5y3A1KWnBRgQkrRA\njboHMQmcUFXVZzGSpPlj1KuY7mZwYlqStEiMugdxDHBvkk3A01ONVfW2XqqSJI3dqAHx4T6LkCTN\nP6Ne5vqXSX4COL6qbkzyUmBJv6VJksZp1Md9/yZwNfBHrWkZ8Gd9FSVJGr9RT1Kfz+DprE/AD18e\n9GN9FSVJGr9RA+LpqnpmaibJIQzug5AkLVCjBsRfJvkg8JL2LurPA/+jv7IkSeM2akCsA3YDdzF4\nwc8N7OVNcpKkhWHUq5im3h/9x/2WI0maL0a9iunBJA/s+ZlhnRVJbk5yb5J7kry3tR+dZGOSb7Wf\nr2jtSfLJJFuT3Dn8/glJ0tybzbOYphwOvAM4eoZ1ngV+p6puS3IEcGuSjcC/Bm6qqouSrGNw+OoD\nwBnA8e3zc8Al7ackaQxG2oOoqkeGPjuq6hPAWTOss7OqbmvTTwL3Mbh/Yg2woXXbAJzdptcAl9fA\n14Gjkiyd/ZAkSQfCqI/7Hj7c8yIGexQjv0siySrgROAW4Niq2tkWfQ84tk0vAx4aWm17a9uJJGnO\njfqP/MeHpp8FtgHvHGXFJC8HvgC8r6qeSPLDZVVVSWZ1P0WStcBagJUrV85mVUnSLIx6FdMv7svG\nkxzKIBw+U1VfbM0PJ1laVTvbIaRdrX0HsGJo9eWtbc9a1gPrASYnJ71ZT5J6MuohpvdPt7yq/qBj\nnQCXAvftsfxa4FzgovbzmqH29yS5gsHJ6ceHDkVJkubYbK5iej2Df8QBfgXYBHxrmnXeCPw6cFeS\nLa3tgwyC4aok5wHf4YVDVTcAZwJbgR8A7x6xNklSD0YNiOXASe1qJJJ8GLi+qv7V3laoqq8B2cvi\n0zr6F4OHAkqS5oFRH7VxLPDM0PwzvHD1kSRpARp1D+JyYFOSL7X5s3nhXgZJ0gI06lVMFyb5c+Dn\nW9O7q+r2/sqSJI3bqIeYAF4KPFFVfwhsT3JcTzVJkuaBUR/W9yEGz0u6oDUdCvxpX0VJksZv1HMQ\nb2fwqIypZyt9tz2ATweRVeuuH9t3b7to2kd3SZqHRj3E9Ey7DLUAkrysv5IkSfPBqAFxVZI/YvCE\n1d8EbsSXB0nSgjbqVUwfa++ifgL4GeD3q2pjr5VJksZqxoBIsgS4sT2wz1CQpEVixkNMVfUc8HyS\nI+egHknSPDHqVUxPMXjo3kbgr6caq+rf9lKVJGnsRg2IL7aPJGmRmDYgkqysqv9XVT53SZIWmZnO\nQfzZ1ESSL/RciyRpHpkpIIbf5/CqPguRJM0vMwVE7WVakrTAzRQQr0vyRJIngde26SeSPJnkielW\nTHJZkl1J7h5q+3CSHUm2tM+ZQ8suSLI1yf1J3rJ/w5Ik7a9pT1JX1ZL92PangP/M4GVDwy6uqo8N\nNyQ5ATgHeA3w48CNSX663YMhSRqD2bwPYlaq6qvA90fsvga4oqqerqoHga3AyX3VJkmaWW8BMY33\nJLmzHYJ6RWtbBjw01Gd7a5MkjclcB8QlwE8Cq4GdwMdnu4Eka5NsTrJ59+7dB7o+SVIzpwFRVQ9X\n1XNV9TyDx4VPHUbaAawY6rq8tXVtY31VTVbV5MTERL8FS9IiNqcBkWTp0OzbgakrnK4FzklyWHvX\n9fHAprmsTZL0o0Z9FtOsJfkccApwTJLtwIeAU5KsZnBPxTbgtwCq6p4kVwH3As8C53sFkySNV28B\nUVXv6mi+dJr+FwIX9lWPJGl2xnEVkyTpIGBASJI6GRCSpE69nYOQhq1ad/1YvnfbRWeN5XulhcA9\nCElSJwNCktTJgJAkdTIgJEmdDAhJUicDQpLUyYCQJHUyICRJnQwISVInA0KS1MmAkCR1MiAkSZ0M\nCElSp94CIsllSXYluXuo7egkG5N8q/18RWtPkk8m2ZrkziQn9VWXJGk0fe5BfAo4fY+2dcBNVXU8\ncFObBzgDOL591gKX9FiXJGkEvQVEVX0V+P4ezWuADW16A3D2UPvlNfB14KgkS/uqTZI0s7k+B3Fs\nVe1s098Djm3Ty4CHhvptb22SpDEZ2xvlqqqS1GzXS7KWwWEoVq5cecDr0sIyrjfZgW+z08Fvrvcg\nHp46dNR+7mrtO4AVQ/2Wt7a/p6rWV9VkVU1OTEz0WqwkLWZzHRDXAue26XOBa4baf6NdzfQG4PGh\nQ1GSpDHo7RBTks8BpwDHJNkOfAi4CLgqyXnAd4B3tu43AGcCW4EfAO/uqy5J0mh6C4iqetdeFp3W\n0beA8/uqRZI0e95JLUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE5jexaTtNCN6zlQPgNK\nB4p7EJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROY7mTOsk24EngOeDZ\nqppMcjRwJbAK2Aa8s6oeHUd90sHMO7h1oIxzD+IXq2p1VU22+XXATVV1PHBTm5ckjcl8OsS0BtjQ\npjcAZ4+xFkla9MYVEAV8OcmtSda2tmOrameb/h5w7HhKkyTB+J7m+qaq2pHkx4CNSb45vLCqKkl1\nrdgCZS3AypUr+69UkhapsexBVNWO9nMX8CXgZODhJEsB2s9de1l3fVVNVtXkxMTEXJUsSYvOnAdE\nkpclOWJqGvhl4G7gWuDc1u1c4Jq5rk2S9IJxHGI6FvhSkqnv/2xV/c8k3wCuSnIe8B3gnWOoTZLU\nzHlAVNUDwOs62h8BTpvreiRJ3ebTZa6SpHnEgJAkdTIgJEmdxnUfhKQFZlzPgAKfA9UX9yAkSZ0M\nCElSJwNCktTJgJAkdTIgJEmdvIpJ0kHPt+j1wz0ISVIn9yAkaR8t9Hs/3IOQJHUyICRJnQwISVIn\nA0KS1MmAkCR1mncBkeT0JPcn2Zpk3bjrkaTFal4FRJIlwH8BzgBOAN6V5ITxViVJi9O8CgjgZGBr\nVT1QVc8AVwBrxlyTJC1K8y0glgEPDc1vb22SpDl20N1JnWQtsLbNPpXk/n3c1DHAXx2Yqg4ajnlx\ncMyLQD66X2P+iVE6zbeA2AGsGJpf3tp+qKrWA+v394uSbK6qyf3dzsHEMS8OjnlxmIsxz7dDTN8A\njk9yXJIXA+cA1465JklalObVHkRVPZvkPcD/ApYAl1XVPWMuS5IWpXkVEABVdQNwwxx81X4fpjoI\nOebFwTEvDr2POVXV93dIkg5C8+0chCRpnlgwATHTIzqSHJbkyrb8liSrhpZd0NrvT/KWUbc5bj2N\n+bIku5LcPTejmJ0DPeYkK5LcnOTeJPckee/cjWY0PYz58CSbktzRxvyRuRvNzPr4u27LliS5Pcl1\n/Y9idnr63/K2JHcl2ZJk8z4VVlUH/YfBCe1vA68CXgzcAZywR5/fBv5bmz4HuLJNn9D6HwYc17az\nZJRtLrQxt2W/AJwE3D3uMc7R73kpcFLrcwTwfxf67xkI8PLW51DgFuAN4x5rn3/Xbfn7gc8C1417\nnHMxZmAbcMz+1LZQ9iBGeUTHGmBDm74aOC1JWvsVVfV0VT0IbG3bm++P/ehjzFTVV4Hvz8UA9sEB\nH3NV7ayq2wCq6kngPubX3ft9jLmq6qnW/9D2mS8nI3v5u06yHDgL+JM5GMNs9TLmA2GhBMQoj+j4\nYZ+qehZ4HHjlNOvO98d+9DHm+a7XMbfd9hMZ/D/q+aKXMbfDLVuAXcDGqpovY+7rd/wJ4HeB5w98\nyfutrzEX8OUkt2bwBIpZWygBIe2XJC8HvgC8r6qeGHc9fauq56pqNYOnFZyc5GfHXVNfkrwV2FVV\nt467ljn2pqo6icHTsc9P8guz3cBCCYgZH9Ex3CfJIcCRwCPTrDvKNsepjzHPd72MOcmhDMLhM1X1\nxV4q33e9/p6r6jHgZuD0A1r1vutjvG8E3pZkG4PDN6cm+dM+it9HvfyOq2rq5y7gS+zLoadxn6A5\nQCd5DgEeYHCSZuokz2v26HM+P3qS56o2/Rp+9CTPAwxOGs24zYU25qH1VjE/T1L38XsOcDnwiXGP\nbw7HPAEc1fq8BPjfwFvHPda+/65bn1OYfyep+/gdvww4ovV5GfB/gNNnXdu4/+McwP/IZzK4AuXb\nwO+1tv8AvK1NHw58nsFJnE3Aq4bW/b223v3AGdNtcz59ehrz54CdwN8xOJ553rjH2eeYgTcxOFZ7\nJ7Clfc4c9zh7HvNrgdvbmO8Gfn/cY+z773po+SnMs4Do6Xf8KgbBcQdwz77+++Wd1JKkTgvlHIQk\n6QAzICRJnQwISVInA0KS1MmAkCR1MiAkSZ0MCElSJwNCktTp/wMIc4rcV2o3WQAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cd81ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dummies[(df_dummies['impressions'] > 10000)]['CTR'].plot(kind='hist',range=[0, 0.005])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, removing low volume impression rows not only removed high-value outliers, they also removed a lot of 0% CTR rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the **median** as our bin cutoff, we would split at 0.10% CTR.\n",
    "\n",
    "Industry benchmarks from __[Google](http://www.richmediagallery.com/learn/benchmarks)__ have all US display media averaging between 0.07%-0.09% CTR. \n",
    "\n",
    "This is roughly in-line with the median we see in our data. (It's promising that our mean is a good chunk above the industry average, at 0.16%.) \n",
    "\n",
    "So, we'll use **0.10%** as the cutoff for our binary \"good/bad\" CTR values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Categorize CTRs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies['ctr_bin'] = np.where(df['CTR']>=0.0010,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3278\n",
       "1    1426\n",
       "Name: ctr_bin, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies['ctr_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a null model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to level set, the \"null\" percentage I get from summing the count of 1s in \"ctr_bin\" is saying, \"With no information other than the training data results—no knowledge about any factors effect on CTR, etc—our best guess as to what makes a good/bad CTR and how many good/bad CTRs would be in a data set is just whatever the percentage of \"good CTR\" make up this training dataset.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30314625850340138"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_null = sum(df_dummies['ctr_bin'])/float(len(df.index))\n",
    "y_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split data new, since Y variable is now ctr_bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dummies.columns[15:464]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols2 = df_dummies.columns[15:464]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dummies[feature_cols2]\n",
    "y = df_dummies['ctr_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave CV to LogisticRegressionCV() function in optimization section?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an actual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83151740632474092"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_train)\n",
    "logreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before:** Our model was 80% accurate on training data.\n",
    "\n",
    "**After adding in order-ad_unit_1 interactive feature:** Our model is now at 83% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778958554729\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "acc = logreg.score(X_test,y_test)\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before**: Our model was 76% accurate on the test data.\n",
    "\n",
    "**After adding in order-ad_unit_1 interactive feature:** Our model is now at 78% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate AUROC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70899796481582122"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc = metrics.roc_auc_score(\n",
    "    y_true=y_test,\n",
    "    y_score=y_pred,\n",
    "    average=None\n",
    ")\n",
    "auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[581,  73],\n",
       "       [135, 152]])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.89      0.85       654\n",
      "          1       0.68      0.53      0.59       287\n",
      "\n",
      "avg / total       0.77      0.78      0.77       941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52961672473867594"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = metrics.recall_score(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'AUROC': 0.70899796481582122,\n",
       "  'accuracy': 0.77895855472901165,\n",
       "  'model_name': 'LogReg_Bin',\n",
       "  'recall': 0.52961672473867594}]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add_score(model_name,accuracy,AUROC,recall)\n",
    "add_score('LogReg_Bin',acc,auroc,recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Follow-Up:** To account for unbalanced data sets, apply weighting to down-sample/balance out the data.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Run balanced model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_bal = linear_model.LogisticRegression(\n",
    "    class_weight='balanced'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_bal.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79883072017007706"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logreg_bal.predict(X_train)\n",
    "logreg_bal.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73113708820403822"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logreg_bal.predict(X_test)\n",
    "acc = logreg_bal.score(X_test,y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So overall model accuracy went from 76% down to 73%, but ideally our recall and precision increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate AUROC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73227471789789966"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc = metrics.roc_auc_score(\n",
    "    y_true=y_test,\n",
    "    y_score=y_pred,\n",
    "    average=None\n",
    ")\n",
    "auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, AUROC went up from 70% to 73%, so overall unpredictability decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[477, 177],\n",
       "       [ 76, 211]])"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.73      0.79       654\n",
      "          1       0.54      0.74      0.63       287\n",
      "\n",
      "avg / total       0.77      0.73      0.74       941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall** is better, more balanced, but precision is less balanced. We care about fewer false negatives, so recall is more relevant, anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73519163763066198"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = metrics.recall_score(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'AUROC': 0.70899796481582122,\n",
       "  'accuracy': 0.77895855472901165,\n",
       "  'model_name': 'LogReg_Bin',\n",
       "  'recall': 0.52961672473867594},\n",
       " {'AUROC': 0.73227471789789966,\n",
       "  'accuracy': 0.73113708820403822,\n",
       "  'model_name': 'LogReg_Bin_Bal',\n",
       "  'recall': 0.73519163763066198}]"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add_score(model_name,accuracy,AUROC,recall)\n",
    "add_score('LogReg_Bin_Bal',acc,auroc,recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do the coefficients mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in logreg.coef_[0]:\n",
    "    coefficients.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = list(feature_cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert coefficient values to logodds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logodds_to_prob(x):\n",
    "    logodds = x\n",
    "    odds = np.exp(logodds)\n",
    "    prob = odds/(1+odds)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = logodds_to_prob(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_coef = pd.DataFrame(\n",
    "{\n",
    "    'feature': features_list,\n",
    "    'coef': coefficients,\n",
    "    'prob': prob\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_coef.sort_values(by='coef',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_coef.sort_values(by='coef',ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intuition here is a little weird. A -2.445 logodds still converts to a positive probability, when in reality that features hould probably be decreasing probability… Or perhaps it's anything underneath a threshold (since our values are always between 0 and 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like specific **creatives (orders)** and **placements** make the biggest impact:\n",
    "- **728x90** perofrms really badly; don't recommend this creative size.\n",
    "- You also don't want to place any of the ads **below-the-fold** (these are the billboard5s and billboard6s).\n",
    "\n",
    "This makes me wonder if I should have actually paired ad placement and device category together, as well as creative and ad_unit_1, and then removed device category all together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:** Tried the above, adding both columns (and removing their old non-paired counterparts to avoid unnecessary collinearity) increases model accuracy by a good 2-3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize by tuning C + adding CV (GridSearchCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h/t Chris Albon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search using 10-fold cross validation\n",
    "clf = GridSearchCV(logreg, hyperparameters, cv=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit grid search\n",
    "best_model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best Penalty:', 'l2')\n",
      "('Best C:', 2.7825594022071245)\n",
      "('Best Parameter', {'penalty': 'l2', 'C': 2.7825594022071245})\n"
     ]
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Best Parameter', best_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict target vector\n",
    "y_pred = best_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782088758969\n",
      "LogisticRegression(C=2.7825594022071245, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print best_model.best_score_\n",
    "print best_model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Note:** Couldn't figure out how to get AUROC or recall scores from the best estimator, so replicating GridSearchCV with LogisticRegressionCV.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate using LogisticRegressionCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_cv = linear_model.LogisticRegressionCV(\n",
    "    Cs=[2.7825594022071245],\n",
    "    class_weight='balanced',\n",
    "    dual=False,\n",
    "    fit_intercept=True,\n",
    "    intercept_scaling=1,\n",
    "    max_iter=100,\n",
    "    multi_class='ovr',\n",
    "    n_jobs=1,\n",
    "    penalty='l2',\n",
    "    random_state=None,\n",
    "    solver='liblinear',\n",
    "    tol=0.0001,\n",
    "    verbose=0,\n",
    "    cv=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=[2.7825594022071245], class_weight='balanced', cv=10,\n",
       "           dual=False, fit_intercept=True, intercept_scaling=1,\n",
       "           max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2',\n",
       "           random_state=None, refit=True, scoring=None, solver='liblinear',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81264948179643903"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logreg_cv.predict(X_train)\n",
    "logreg_cv.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performance against test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74814027630180657"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logreg_cv.predict(X_test)\n",
    "acc = logreg_cv.score(X_test,y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50101306061398732"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.average_precision_score(\n",
    "    y_true=y_test, \n",
    "    y_score=y_pred, \n",
    "    average=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74939530522434983"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc = metrics.roc_auc_score(\n",
    "    y_true=y_test,\n",
    "    y_score=y_pred,\n",
    "    average=None\n",
    ")\n",
    "auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More slight improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[488, 166],\n",
       "       [ 71, 216]])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.75      0.80       654\n",
      "          1       0.57      0.75      0.65       287\n",
      "\n",
      "avg / total       0.78      0.75      0.76       941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall is more balanced, precision still not so much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7526132404181185"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = metrics.recall_score(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'AUROC': 0.70899796481582122,\n",
       "  'accuracy': 0.77895855472901165,\n",
       "  'model_name': 'LogReg_Bin',\n",
       "  'recall': 0.52961672473867594},\n",
       " {'AUROC': 0.73227471789789966,\n",
       "  'accuracy': 0.73113708820403822,\n",
       "  'model_name': 'LogReg_Bin_Bal',\n",
       "  'recall': 0.73519163763066198},\n",
       " {'AUROC': 0.74939530522434983,\n",
       "  'accuracy': 0.74814027630180657,\n",
       "  'model_name': 'LogReg_Bin_Bal_GSCV',\n",
       "  'recall': 0.7526132404181185}]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add_score(model_name,accuracy,AUROC,recall)\n",
    "add_score('LogReg_Bin_Bal_GSCV',acc,auroc,recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = []\n",
    "for each in logreg_cv.coef_[0]:\n",
    "    coefficients.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = list(feature_cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = logodds_to_prob(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_coef = pd.DataFrame(\n",
    "{\n",
    "    'feature': features_list,\n",
    "    'coef': coefficients,\n",
    "    'prob': prob\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_coef.sort_values(by='coef',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_coef.sort_values(by='coef',ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There hasn't been any actual ranking change, even as the model has improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression with CTR Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method recommended by a data scientist coworker is binning CTRs into high, medium, low ranges. Since our goal is to understand which features most influence higher CTR, it's not necessary for us to know exactly what the end CTR is or to predict a specific CTR.\n",
    "\n",
    "This should be just like the binomial logistic regression above, just with more bins. I imagine it would have higher model performance, since it's more granular? (As long as there isn't too much overfitting.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bin the CTRs\n",
    "\n",
    "Going to split CTRs into 3 vs 4 vs 5 categories and see how that affects performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11d0ba8d0>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAErpJREFUeJzt3X+sZ3V95/HnS0DxB6tYppQCdqCZtjv2B06nlETbpTXy\nsxXdZF1MtxJDOk06pJo2WUfbFNeGhE2sWnddtqiTQqtSrFpndbZ0ILa22Sgz6AgMlHKLuMw4MlPp\nilYjBd/7x/dz6dfpzJ3vZ+ae+/3ee5+P5Jt7zud8zvm+P9wLL875nO/5pqqQJGlSz5h2AZKk5cXg\nkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LU5cRpFzCE0047rdauXTvtMiRpWbnr\nrrv+oarWHK3figyOtWvXsmvXrmmXIUnLSpIvTdLPS1WSpC4GhySpi8EhSepicEiSuhgckqQuBock\nqYvBIUnqYnBIkroYHJKkLivyk+PHa+2WT07lfR++/vKpvK8k9fCMQ5LUxeCQJHUxOCRJXQwOSVIX\ng0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUZLDiSnJ3kU0nu\nS7InyRta+1uT7Euyu70uG9vnzUnmkjyQ5OKx9kta21ySLUPVLEk6uiG/j+NJ4Der6nNJTgHuSrKj\nbXtnVb19vHOS9cCVwIuB7wduT/JDbfN7gFcAe4GdSbZV1X0D1i5JOoLBgqOq9gP72/LXk9wPnLnA\nLlcAt1TVt4EvJpkDzm/b5qrqIYAkt7S+BockTcGSzHEkWQu8BPhsa7omyd1JtiY5tbWdCTwyttve\n1nak9kPfY1OSXUl2HTx4cJFHIEmaN3hwJHke8BHgjVX1OHAD8IPAeYzOSH5vMd6nqm6sqo1VtXHN\nmjWLcUhJ0mEM+p3jSU5iFBofqKqPAlTVo2Pb3wt8oq3uA84e2/2s1sYC7ZKkJTbkXVUB3g/cX1Xv\nGGs/Y6zbq4F72/I24Mokz0pyDrAOuBPYCaxLck6SZzKaQN82VN2SpIUNecbxUuCXgXuS7G5tbwFe\nm+Q8oICHgV8FqKo9SW5lNOn9JLC5qp4CSHINcBtwArC1qvYMWLckaQFD3lX1N0AOs2n7AvtcB1x3\nmPbtC+0nSVo6fnJcktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1\nMTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1\nMTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUpfBgiPJ2Uk+leS+JHuSvKG1vzDJjiQPtp+ntvYk\neXeSuSR3J9kwdqyrWv8Hk1w1VM2SpKMb8ozjSeA3q2o9cAGwOcl6YAtwR1WtA+5o6wCXAuvaaxNw\nA4yCBrgW+GngfODa+bCRJC29wYKjqvZX1efa8teB+4EzgSuAm1q3m4BXteUrgJtr5DPAC5KcAVwM\n7Kiqx6rqH4EdwCVD1S1JWtiSzHEkWQu8BPgscHpV7W+bvgKc3pbPBB4Z221vaztSuyRpCgYPjiTP\nAz4CvLGqHh/fVlUF1CK9z6Yku5LsOnjw4GIcUpJ0GIMGR5KTGIXGB6rqo6350XYJivbzQGvfB5w9\ntvtZre1I7d+lqm6sqo1VtXHNmjWLOxBJ0tOGvKsqwPuB+6vqHWObtgHzd0ZdBXx8rP117e6qC4Cv\ntUtatwEXJTm1TYpf1NokSVNw4oDHfinwy8A9SXa3trcA1wO3Jrka+BLwmrZtO3AZMAd8E3g9QFU9\nluR3gZ2t39uq6rEB65YkLWCw4KiqvwFyhM0vP0z/AjYf4Vhbga2LV50k6Vj5yXFJUheDQ5LUxeCQ\nJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUpeJgiPJjw1d\niCRpeZj0jON/JLkzya8lef6gFUmSZtpEwVFVPwP8EqOvcL0ryQeTvGLQyiRJM2niOY6qehD4beBN\nwL8D3p3kb5P8+6GKkyTNnknnOH48yTuB+4GfB36xqv5tW37ngPVJkmbMpF8d+9+A9wFvqapvzTdW\n1ZeT/PYglUmSZtKkwXE58K2qegogyTOAk6vqm1X1R4NVJ0maOZPOcdwOPHts/TmtTZK0ykwaHCdX\n1TfmV9ryc4YpSZI0yyYNjn9KsmF+JclPAt9aoL8kaYWadI7jjcCHk3wZCPB9wH8crCpJ0syaKDiq\nameSHwF+uDU9UFX/PFxZkqRZNekZB8BPAWvbPhuSUFU3D1KVJGlmTRQcSf4I+EFgN/BUay7A4JCk\nVWbSM46NwPqqqiGLkSTNvknvqrqX0YS4JGmVmzQ4TgPuS3Jbkm3zr4V2SLI1yYEk9461vTXJviS7\n2+uysW1vTjKX5IEkF4+1X9La5pJs6R2gJGlxTXqp6q3HcOw/BP47/3oe5J1V9fbxhiTrgSuBFwPf\nD9ye5Ifa5vcArwD2AjuTbKuq+46hHknSIpj0dty/SvIDwLqquj3Jc4ATjrLPp5OsnbCOK4Bbqurb\nwBeTzAHnt21zVfUQQJJbWl+DQ5KmZNLHqv8K8KfAH7SmM4E/O8b3vCbJ3e1S1qljx3tkrM/e1nak\ndknSlEw6x7EZeCnwODz9pU7fewzvdwOj23rPA/YDv3cMxzisJJuS7Eqy6+DBg4t1WEnSISYNjm9X\n1RPzK0lOZPQ5ji5V9WhVPVVV3wHey79cjtrH6Gtp553V2o7Ufrhj31hVG6tq45o1a3pLkyRNaNLg\n+KskbwGe3b5r/MPA/+p9syRnjK2+mtFtvgDbgCuTPCvJOcA64E5gJ7AuyTlJnsloAn3Bu7kkScOa\n9K6qLcDVwD3ArwLbGX0j4BEl+RBwIXBakr3AtcCFSc5jdLbycDsWVbUnya2MJr2fBDaPfWnUNcBt\njCbjt1bVno7xSZIW2aR3Vc1fWnrvpAeuqtcepvn9C/S/DrjuMO3bGQWVJGkGTPqsqi9ymDmNqjp3\n0SuSJM20nmdVzTsZ+A/ACxe/HEnSrJtocryqvjr22ldV7wIuH7g2SdIMmvRS1Yax1WcwOgPp+S4P\nSdIKMel//Mc/qPckozuiXrPo1UiSZt6kd1X93NCFSJKWh0kvVf3GQtur6h2LU44kadb13FX1U/zL\np7Z/kdEnux8coihJ0uyaNDjOAjZU1ddh9IVMwCer6j8NVZgkaTZN+qyq04EnxtafaG2SpFVm0jOO\nm4E7k3ysrb8KuGmYkiRJs2zSu6quS/K/gZ9pTa+vqs8PV5YkaVZNeqkK4DnA41X1+8De9vhzSdIq\nM+lXx14LvAl4c2s6CfjjoYqSJM2uSc84Xg28EvgngKr6MnDKUEVJkmbXpMHxRFUV7dHqSZ47XEmS\npFk2aXDcmuQPgBck+RXgdjq+1EmStHJMelfV29t3jT8O/DDwO1W1Y9DKJEkz6ajBkeQE4Pb2oEPD\nQpJWuaNeqqqqp4DvJHn+EtQjSZpxk35y/BvAPUl20O6sAqiqXx+kKknSzJo0OD7aXpKkVW7B4Ejy\noqr6v1Xlc6kkScDR5zj+bH4hyUcGrkWStAwcLTgytnzukIVIkpaHowVHHWFZkrRKHW1y/CeSPM7o\nzOPZbZm2XlX1bwatTpI0cxYMjqo6YakKkSQtDz3fxyFJ0nDBkWRrkgNJ7h1re2GSHUkebD9Pbe1J\n8u4kc0nuTrJhbJ+rWv8Hk1w1VL2SpMkMecbxh8Alh7RtAe6oqnXAHW0d4FJgXXttAm6AUdAA1wI/\nDZwPXDsfNpKk6RgsOKrq08BjhzRfAcx/mPAm4FVj7TfXyGcYPb79DOBiYEdVPVZV/8joIYuHhpEk\naQkt9RzH6VW1vy1/BTi9LZ8JPDLWb29rO1L7v5JkU5JdSXYdPHhwcauWJD1tapPj498ouEjHu7Gq\nNlbVxjVr1izWYSVJh1jq4Hi0XYKi/TzQ2vcBZ4/1O6u1HaldkjQlSx0c24D5O6OuAj4+1v66dnfV\nBcDX2iWt24CLkpzaJsUvam2SpCmZ9LHq3ZJ8CLgQOC3JXkZ3R13P6PvLrwa+BLymdd8OXAbMAd8E\nXg9QVY8l+V1gZ+v3tqo6dMJdkrSEBguOqnrtETa9/DB9C9h8hONsBbYuYmmSpOPgJ8clSV0MDklS\nF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklS\nF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklS\nF4NDktTF4JAkdZlKcCR5OMk9SXYn2dXaXphkR5IH289TW3uSvDvJXJK7k2yYRs2SpJFpnnH8XFWd\nV1Ub2/oW4I6qWgfc0dYBLgXWtdcm4IYlr1SS9LQTp13AmCuAC9vyTcBfAm9q7TdXVQGfSfKCJGdU\n1f6pVDmgtVs+ObX3fvj6y6f23pKWl2mdcRTwF0nuSrKptZ0+FgZfAU5vy2cCj4ztu7e1SZKmYFpn\nHC+rqn1JvhfYkeRvxzdWVSWpngO2ANoE8KIXvWjxKpUkfZepnHFU1b728wDwMeB84NEkZwC0nwda\n933A2WO7n9XaDj3mjVW1sao2rlmzZsjyJWlVW/LgSPLcJKfMLwMXAfcC24CrWrergI+35W3A69rd\nVRcAX1uJ8xuStFxM41LV6cDHksy//wer6s+T7ARuTXI18CXgNa3/duAyYA74JvD6pS9ZkjRvyYOj\nqh4CfuIw7V8FXn6Y9gI2L0FpkqQJ+MlxSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdZml\np+Nqiqb1ZF6fyistP55xSJK6GBySpC4GhySpi8EhSepicEiSunhXlabKu7mk5cczDklSF4NDktTF\n4JAkdTE4JEldDA5JUhfvqtKqNK27ucA7urT8ecYhSepicEiSunipSlpifuhRy51nHJKkLp5xSKuE\nNwRosXjGIUnqYnBIkroYHJKkLs5xSBqcd5KtLMsmOJJcAvw+cALwvqq6fsolSZpx07whYFqWIiyX\nxaWqJCcA7wEuBdYDr02yfrpVSdLqtCyCAzgfmKuqh6rqCeAW4Iop1yRJq9JyCY4zgUfG1ve2NknS\nEls2cxxHk2QTsKmtfiPJA8dxuNOAfzj+qpaV1Tbm1TZecMyrQv7rcY35BybptFyCYx9w9tj6Wa3t\naVV1I3DjYrxZkl1VtXExjrVcrLYxr7bxgmNeLZZizMvlUtVOYF2Sc5I8E7gS2DblmiRpVVoWZxxV\n9WSSa4DbGN2Ou7Wq9ky5LElalZZFcABU1XZg+xK93aJc8lpmVtuYV9t4wTGvFoOPOVU19HtIklaQ\n5TLHIUmaESs+OJJckuSBJHNJthxm+7OS/Enb/tkka8e2vbm1P5Dk4kmPOW0DjXlrkgNJ7l2aUfRZ\n7DEnOTvJp5Lcl2RPkjcs3WgmM8CYT05yZ5IvtDH/l6UbzWSG+Ntu205I8vkknxh+FJMb6N/lh5Pc\nk2R3kl3HVFhVrdgXo4n0vwfOBZ4JfAFYf0ifXwP+Z1u+EviTtry+9X8WcE47zgmTHHOljblt+1lg\nA3DvtMe4RL/nM4ANrc8pwN+t9N8zEOB5rc9JwGeBC6Y91qH/ttv23wA+CHxi2uMcerzAw8Bpx1Pb\nSj/jmORRJVcAN7XlPwVeniSt/Zaq+nZVfRGYa8eb9cefDDFmqurTwGNLMYBjsOhjrqr9VfU5gKr6\nOnA/s/W0giHGXFX1jdb/pPaapUnQQf62k5wFXA68bwnG0GOQ8S6GlR4ckzyq5Ok+VfUk8DXgexbY\nd9YffzLEmGfdoGNup/8vYfR/4LNikDG3Sza7gQPAjqpa8WMG3gX8Z+A7i1/ycRlqvAX8RZK7Mnri\nRreVHhzScUnyPOAjwBur6vFp1zO0qnqqqs5j9HSG85P86LRrGlKSXwAOVNVd065lCb2sqjYwetr4\n5iQ/23uAlR4cR31UyXifJCcCzwe+usC+kxxzmoYY86wbZMxJTmIUGh+oqo8OUvmxG/T3XFX/D/gU\ncMmiVn18hhjzS4FXJnmY0aWgn0/yx0MUfwwG+R1X1fzPA8DHOJZLWNOeABp4culE4CFGk0Pzk0sv\nPqTPZr57cunWtvxivnty6SFGk1VHPeZKG/PYfmuZzcnxIX7PAW4G3jXt8S3hmNcAL2h9ng38NfAL\n0x7rUvxttz4XMluT40P8jp8LnNL6PBf4P8Al3bVN+x/OEvzDv4zRHTF/D/xWa3sb8Mq2fDLwYUaT\nR3cC547t+1ttvweASxc65iy9Bhrzh4D9wD8zul569bTHOeSYgZcxuhZ8N7C7vS6b9jgHHvOPA59v\nY74X+J1pj3Ep/rbHtl/IDAXHQL/jcxkFyheAPcf63y8/OS5J6rLS5zgkSYvM4JAkdTE4JEldDA5J\nUheDQ5LUxeCQJHUxOCRJXQwOSVKX/w/tSuTh/fyL/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11919fc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dummies['CTR'].plot(kind='hist', range=[0, 0.005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1568\n",
      "3136\n",
      "4704\n"
     ]
    }
   ],
   "source": [
    "print df_dummies['CTR'].count()/3\n",
    "print df_dummies['CTR'].count()/3*2\n",
    "print df_dummies['CTR'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ctr = df_dummies['CTR'].sort_values(ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.000853533629225\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print df_ctr[1568]\n",
    "print df_ctr[3136]\n",
    "print df_ctr[4703]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binner(num):\n",
    "    for each in range(0,num):\n",
    "        bin = df_dummies['CTR'].count()/num*each\n",
    "        print df_ctr[bin]\n",
    "    print df_ctr[4703]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.000199215719169\n",
      "0.00135961930659\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "binner(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00055277269016\n",
      "0.00173310225303\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "binner(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure how the unbalanced nature of the dataset is going to affect model performance. Actually seems like the only reasonable bin is using 3 groups: \n",
    "- [0,0.000199215719169)\n",
    "- [0.000199215719169,0.00135961930659)\n",
    "- [0.00135961930659,0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a feeling this model is actually going to be poorer than the previous, because that final bucket is going to be heavily skewed by outliers… "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weight of evidence (WOE)** could be an interesting way of binning and measuring my caetgorical dependent variables… __[link](http://multithreaded.stitchfix.com/blog/2015/08/13/weight-of-evidence/)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Categorize the CTRs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-0.00000000000001, 0.000199215719169, 0.00135961930659, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['low','good','great']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low      2352\n",
       "good     1177\n",
       "great    1175\n",
       "Name: CTR, dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr_bins = pd.cut(df_dummies['CTR'], bins, labels=group_names)\n",
    "ctr_bins.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies['ctr_bins'] = pd.cut(df_dummies['CTR'], bins, labels=group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null model\n",
    "\n",
    "Is still the same as null model from binomial logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reassign y value, but train/test/split sets still remain the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_dummies['ctr_bins']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an actual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilogreg = linear_model.LogisticRegression(multi_class='multinomial', class_weight='balanced', solver='newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "          random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilogreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial regression doesn't accept the best solver from the previous model, **liblinear**. A bit over my head, so just switching to a solver that works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80972628222163168"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = multilogreg.predict(X_train)\n",
    "multilogreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooh, this model is a *bit* better than the binomial linear regression against the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73751328374070135"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = multilogreg.predict(X_test)\n",
    "acc = multilogreg.score(X_test,y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73588423957634075"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc = metrics.roc_auc_score(\n",
    "    y_true=y_test,\n",
    "    y_score=y_pred,\n",
    "    average=None\n",
    ")\n",
    "auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvements across all metrics. Now to optimize again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[484, 170],\n",
       "       [ 77, 210]])"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.74      0.80       654\n",
      "          1       0.55      0.73      0.63       287\n",
      "\n",
      "avg / total       0.77      0.74      0.75       941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No real difference to precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73170731707317072"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = metrics.recall_score(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'AUROC': 0.70899796481582122,\n",
       "  'accuracy': 0.77895855472901165,\n",
       "  'model_name': 'LogReg_Bin',\n",
       "  'recall': 0.52961672473867594},\n",
       " {'AUROC': 0.73227471789789966,\n",
       "  'accuracy': 0.73113708820403822,\n",
       "  'model_name': 'LogReg_Bin_Bal',\n",
       "  'recall': 0.73519163763066198},\n",
       " {'AUROC': 0.74939530522434983,\n",
       "  'accuracy': 0.74814027630180657,\n",
       "  'model_name': 'LogReg_Bin_Bal_GSCV',\n",
       "  'recall': 0.7526132404181185},\n",
       " {'AUROC': 0.73588423957634075,\n",
       "  'accuracy': 0.73751328374070135,\n",
       "  'model_name': 'LogReg_Multi',\n",
       "  'recall': 0.73170731707317072}]"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add_score(model_name,accuracy,AUROC,recall)\n",
    "add_score('LogReg_Multi',acc,auroc,recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = []\n",
    "for each in multilogreg.coef_[0]:\n",
    "    coefficients.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = list(feature_cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = logodds_to_prob(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_coef = pd.DataFrame(\n",
    "{\n",
    "    'feature': features_list,\n",
    "    'coef': coefficients,\n",
    "    'prob': prob\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_coef.sort_values(by='coef',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_coef.sort_values(by='coef',ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best and worst features are basically the same against previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize by tuning C (GridSearch) + adding CV again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regularization penalty space\n",
    "penalty = ['l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search using 10-fold cross validation\n",
    "clf = GridSearchCV(multilogreg, hyperparameters, cv=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit grid search\n",
    "best_model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best Penalty:', 'l2')\n",
      "('Best C:', 2.7825594022071245)\n"
     ]
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict target vector\n",
    "y_pred = best_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.759500398618\n",
      "LogisticRegression(C=2.7825594022071245, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
      "          random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "          warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print best_model.best_score_\n",
    "print best_model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just slightly better than the other model. (By 0.03%.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate using LogisticRegressionCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilogreg_cv = linear_model.LogisticRegressionCV(\n",
    "    Cs=[2.7825594022071245],\n",
    "    class_weight=None,\n",
    "    dual=False,\n",
    "    fit_intercept=True,\n",
    "    intercept_scaling=1,\n",
    "    max_iter=100,\n",
    "    multi_class='multinomial',\n",
    "    n_jobs=1,\n",
    "    penalty='l2',\n",
    "    random_state=None,\n",
    "    solver='newton-cg',\n",
    "    tol=0.0001,\n",
    "    verbose=0,\n",
    "    cv=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=[2.7825594022071245], class_weight=None, cv=10,\n",
       "           dual=False, fit_intercept=True, intercept_scaling=1,\n",
       "           max_iter=100, multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "           random_state=None, refit=True, scoring=None, solver='newton-cg',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilogreg_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69891044379484457"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = multilogreg_cv.predict(X_train)\n",
    "multilogreg_cv.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oof, this model's performance went way down!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70138150903294372"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = multilogreg_cv.predict(X_test)\n",
    "acc = multilogreg_cv.score(X_test,y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31952441431200407"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.average_precision_score(\n",
    "    y_true=y_test, \n",
    "    y_score=y_pred, \n",
    "    average=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51045296167247389"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc = metrics.roc_auc_score(\n",
    "    y_true=y_test,\n",
    "    y_score=y_pred,\n",
    "    average=None\n",
    ")\n",
    "auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, this model didn't perform better than binomial logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[654,   0],\n",
       "       [281,   6]])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      1.00      0.82       654\n",
      "          1       1.00      0.02      0.04       287\n",
      "\n",
      "avg / total       0.79      0.70      0.58       941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haha this is so bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020905923344947737"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = metrics.recall_score(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'AUROC': 0.70899796481582122,\n",
       "  'accuracy': 0.77895855472901165,\n",
       "  'model_name': 'LogReg_Bin',\n",
       "  'recall': 0.52961672473867594},\n",
       " {'AUROC': 0.73227471789789966,\n",
       "  'accuracy': 0.73113708820403822,\n",
       "  'model_name': 'LogReg_Bin_Bal',\n",
       "  'recall': 0.73519163763066198},\n",
       " {'AUROC': 0.74939530522434983,\n",
       "  'accuracy': 0.74814027630180657,\n",
       "  'model_name': 'LogReg_Bin_Bal_GSCV',\n",
       "  'recall': 0.7526132404181185},\n",
       " {'AUROC': 0.73588423957634075,\n",
       "  'accuracy': 0.73751328374070135,\n",
       "  'model_name': 'LogReg_Multi',\n",
       "  'recall': 0.73170731707317072},\n",
       " {'AUROC': 0.51045296167247389,\n",
       "  'accuracy': 0.70138150903294372,\n",
       "  'model_name': 'LogReg_Multi_GSCV',\n",
       "  'recall': 0.020905923344947737}]"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add_score(model_name,accuracy,AUROC,recall)\n",
    "add_score('LogReg_Multi_GSCV',acc,auroc,recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients Exploration (just for kicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = []\n",
    "for each in multilogreg_cv.coef_[0]:\n",
    "    coefficients.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = list(feature_cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = logodds_to_prob(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_coef = pd.DataFrame(\n",
    "{\n",
    "    'feature': features_list,\n",
    "    'coef': coefficients,\n",
    "    'prob': prob\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feature</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>2.125588</td>\n",
       "      <td>ad_unit_3_device-_native-desktop</td>\n",
       "      <td>0.893365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2.023306</td>\n",
       "      <td>ad_unit_1_order-_7324974_Behr Exterior 2017_5....</td>\n",
       "      <td>0.883222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1.709523</td>\n",
       "      <td>ad_unit_1_order-_7902294_Whirlpool KitchenAid ...</td>\n",
       "      <td>0.846774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>1.634333</td>\n",
       "      <td>ad_unit_3_device-_leaderboardfooter2-desktop</td>\n",
       "      <td>0.836762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>1.555509</td>\n",
       "      <td>ad_unit_3_device-_leaderboard2-desktop</td>\n",
       "      <td>0.825708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>1.500316</td>\n",
       "      <td>ad_unit_3_device-_leaderboardac-desktop</td>\n",
       "      <td>0.817622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1.469707</td>\n",
       "      <td>ad_unit_1_order-_5406534_DIZ/WDH/020_USA_FY17_...</td>\n",
       "      <td>0.813013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>1.451609</td>\n",
       "      <td>ad_unit_1_order-_6923694_Xiaflex DC Display Ca...</td>\n",
       "      <td>0.810246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1.436562</td>\n",
       "      <td>ad_unit_1_order-_6317454_Trulicity Display F/Y...</td>\n",
       "      <td>0.807922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1.416987</td>\n",
       "      <td>ad_unit_3_device-_billboard-desktop</td>\n",
       "      <td>0.804866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coef                                            feature      prob\n",
       "444  2.125588                   ad_unit_3_device-_native-desktop  0.893365\n",
       "254  2.023306  ad_unit_1_order-_7324974_Behr Exterior 2017_5....  0.883222\n",
       "291  1.709523  ad_unit_1_order-_7902294_Whirlpool KitchenAid ...  0.846774\n",
       "443  1.634333       ad_unit_3_device-_leaderboardfooter2-desktop  0.836762\n",
       "436  1.555509             ad_unit_3_device-_leaderboard2-desktop  0.825708\n",
       "441  1.500316            ad_unit_3_device-_leaderboardac-desktop  0.817622\n",
       "133  1.469707  ad_unit_1_order-_5406534_DIZ/WDH/020_USA_FY17_...  0.813013\n",
       "223  1.451609  ad_unit_1_order-_6923694_Xiaflex DC Display Ca...  0.810246\n",
       "157  1.436562  ad_unit_1_order-_6317454_Trulicity Display F/Y...  0.807922\n",
       "415  1.416987                ad_unit_3_device-_billboard-desktop  0.804866"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_coef.sort_values(by='coef',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feature</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>-1.264453</td>\n",
       "      <td>ad_unit_1_order-_8032374_VAL_ONE_003_Digital C...</td>\n",
       "      <td>0.220208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-1.265617</td>\n",
       "      <td>ad_unit_1_order-_20001921_Stiolto Q3/Q4 2017_7...</td>\n",
       "      <td>0.220009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-1.309908</td>\n",
       "      <td>ad_unit_1_order-_20080945_Walgreens FY18-MEDD-...</td>\n",
       "      <td>0.212502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>-1.355976</td>\n",
       "      <td>ad_unit_1_order-_7030614_Dignity Health_CHMC O...</td>\n",
       "      <td>0.204895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>-1.383032</td>\n",
       "      <td>ad_unit_1_order-_7857534_FCAC Always On Campai...</td>\n",
       "      <td>0.200523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>-1.454826</td>\n",
       "      <td>ad_unit_3_device-_billboardmobile2-mobile</td>\n",
       "      <td>0.189260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-1.538015</td>\n",
       "      <td>ad_unit_1_order-_20001921_Stiolto Q3/Q4 2017_7...</td>\n",
       "      <td>0.176824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>-1.590701</td>\n",
       "      <td>ad_unit_1_order-_The Spruce - QA &amp; Testing-The...</td>\n",
       "      <td>0.169285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.610347</td>\n",
       "      <td>ad_unit_1_order-_19999038_The Home Depot_Q3 Sm...</td>\n",
       "      <td>0.166540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>-2.246013</td>\n",
       "      <td>ad_unit_3_device-_billboard6-mobile</td>\n",
       "      <td>0.095694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coef                                            feature      prob\n",
       "311 -1.264453  ad_unit_1_order-_8032374_VAL_ONE_003_Digital C...  0.220208\n",
       "31  -1.265617  ad_unit_1_order-_20001921_Stiolto Q3/Q4 2017_7...  0.220009\n",
       "80  -1.309908  ad_unit_1_order-_20080945_Walgreens FY18-MEDD-...  0.212502\n",
       "237 -1.355976  ad_unit_1_order-_7030614_Dignity Health_CHMC O...  0.204895\n",
       "286 -1.383032  ad_unit_1_order-_7857534_FCAC Always On Campai...  0.200523\n",
       "431 -1.454826          ad_unit_3_device-_billboardmobile2-mobile  0.189260\n",
       "30  -1.538015  ad_unit_1_order-_20001921_Stiolto Q3/Q4 2017_7...  0.176824\n",
       "396 -1.590701  ad_unit_1_order-_The Spruce - QA & Testing-The...  0.169285\n",
       "26  -1.610347  ad_unit_1_order-_19999038_The Home Depot_Q3 Sm...  0.166540\n",
       "426 -2.246013                ad_unit_3_device-_billboard6-mobile  0.095694"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_coef.sort_values(by='coef',ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same features are generally still in the top and bottom 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set max_features to auto.\n",
    "\n",
    "Set n_estimators to 150 for now, come back and test for ideal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\n",
       "            oob_score=True, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestClassifier(\n",
    "    n_estimators=150, \n",
    "    max_features='auto', \n",
    "    oob_score=True, \n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "rfreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame({'feature':feature_cols2, 'importance':rfreg.feature_importances_}).sort_values(by='importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, random forest took big groupings (e.g. ad placements), and the specific ad campaigns/creatives' effects are diminished.\n",
    "\n",
    "Also, **728x90s** which we know perform rather poorly are at the top of the list for feature importance, because it's a **strong** influencer of CTR, but we don't technically know which way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute OOB Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.758437416955\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute the out-of-bag R-squared score.\n",
    "print(rfreg.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98299229338293914"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "### whoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74707757704569611"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = rfreg.score(X_test,y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. This is the best performing model! Although I lose interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6635765964474849"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc = metrics.roc_auc_score(\n",
    "    y_true=y_test,\n",
    "    y_score=y_pred,\n",
    "    average=None\n",
    ")\n",
    "auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[574,  80],\n",
       "       [158, 129]])"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.88      0.83       654\n",
      "          1       0.62      0.45      0.52       287\n",
      "\n",
      "avg / total       0.73      0.75      0.73       941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision more balanced, but recall is less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44947735191637633"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = metrics.recall_score(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'AUROC': 0.70899796481582122,\n",
       "  'accuracy': 0.77895855472901165,\n",
       "  'model_name': 'LogReg_Bin',\n",
       "  'recall': 0.52961672473867594},\n",
       " {'AUROC': 0.73227471789789966,\n",
       "  'accuracy': 0.73113708820403822,\n",
       "  'model_name': 'LogReg_Bin_Bal',\n",
       "  'recall': 0.73519163763066198},\n",
       " {'AUROC': 0.74939530522434983,\n",
       "  'accuracy': 0.74814027630180657,\n",
       "  'model_name': 'LogReg_Bin_Bal_GSCV',\n",
       "  'recall': 0.7526132404181185},\n",
       " {'AUROC': 0.73588423957634075,\n",
       "  'accuracy': 0.73751328374070135,\n",
       "  'model_name': 'LogReg_Multi',\n",
       "  'recall': 0.73170731707317072},\n",
       " {'AUROC': 0.51045296167247389,\n",
       "  'accuracy': 0.70138150903294372,\n",
       "  'model_name': 'LogReg_Multi_GSCV',\n",
       "  'recall': 0.020905923344947737},\n",
       " {'AUROC': 0.6635765964474849,\n",
       "  'accuracy': 0.74707757704569611,\n",
       "  'model_name': 'RandForestClass',\n",
       "  'recall': 0.44947735191637633}]"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add_score(model_name,accuracy,AUROC,recall)\n",
    "add_score('RandForestClass',acc,auroc,recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_features & n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_options = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = []\n",
    "score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for each in max_features_options:\n",
    "    rfreg = RandomForestClassifier(\n",
    "    n_estimators=150, \n",
    "    max_features=each, \n",
    "    oob_score=True, \n",
    "    random_state=1\n",
    ")\n",
    "    rfreg.fit(X_train, y_train)\n",
    "    max_features.append(each)\n",
    "    score.append(rfreg.score(X_test,y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.730074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.733262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.750266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.751328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.744952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.751328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.755579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.746015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.753454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.755579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.753454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.751328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.751328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.749203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.747078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.748140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.753454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.747078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.750266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.748140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_features     score\n",
       "0              1  0.730074\n",
       "1              2  0.733262\n",
       "2              3  0.750266\n",
       "3              4  0.751328\n",
       "4              5  0.744952\n",
       "5              6  0.751328\n",
       "6              7  0.755579\n",
       "7              8  0.746015\n",
       "8              9  0.753454\n",
       "9             10  0.755579\n",
       "10            11  0.753454\n",
       "11            12  0.751328\n",
       "12            13  0.751328\n",
       "13            14  0.749203\n",
       "14            15  0.747078\n",
       "15            16  0.748140\n",
       "16            17  0.753454\n",
       "17            18  0.747078\n",
       "18            19  0.750266\n",
       "19            20  0.748140"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features_tuning = pd.DataFrame(\n",
    "{\n",
    "    'max_features': max_features,\n",
    "    'score': score\n",
    "})\n",
    "max_features_tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peaked at 10. max_features should be set to **10**. Curious which 10 features these will be…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_options = [1,5,10,15,20,50,100,150,250,400,500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = []\n",
    "score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jennifersun/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.py:451: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/jennifersun/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for each in n_estimators_options:\n",
    "    rfreg = RandomForestClassifier(\n",
    "    n_estimators=each, \n",
    "    max_features=10, \n",
    "    oob_score=True, \n",
    "    random_state=1\n",
    ")\n",
    "    rfreg.fit(X_train, y_train)\n",
    "    n_estimators.append(each)\n",
    "    score.append(rfreg.score(X_test,y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.693943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.722635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.740701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.744952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0.740701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>0.744952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>0.758767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>150</td>\n",
       "      <td>0.755579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>250</td>\n",
       "      <td>0.761955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>400</td>\n",
       "      <td>0.760893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>500</td>\n",
       "      <td>0.759830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators     score\n",
       "0              1  0.693943\n",
       "1              5  0.722635\n",
       "2             10  0.740701\n",
       "3             15  0.744952\n",
       "4             20  0.740701\n",
       "5             50  0.744952\n",
       "6            100  0.758767\n",
       "7            150  0.755579\n",
       "8            250  0.761955\n",
       "9            400  0.760893\n",
       "10           500  0.759830"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators_tuning = pd.DataFrame(\n",
    "{\n",
    "    'n_estimators': n_estimators,\n",
    "    'score': score\n",
    "})\n",
    "n_estimators_tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**250 trees** it is — at this point these miniscule improvements to the model are probably overfitting my model and not really adding much to interpretability. But I'm doing for the sake of the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit model with tuned hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=10, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "            oob_score=True, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestClassifier(\n",
    "    n_estimators=250, \n",
    "    max_features=10, \n",
    "    oob_score=True, \n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "rfreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame({'feature':feature_cols2, 'importance':rfreg.feature_importances_}).sort_values(by='importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.759766144034\n",
      "0.982992293383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7619553666312433"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compute the out-of-bag R-squared score.\n",
    "print(rfreg.oob_score_)\n",
    "print rfreg.score(X_train,y_train)\n",
    "acc = rfreg.score(X_test,y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun, model accuracy went up by 2% … but didn't change interpretability one bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[586,  68],\n",
       "       [156, 131]])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.90      0.84       654\n",
      "          1       0.66      0.46      0.54       287\n",
      "\n",
      "avg / total       0.75      0.76      0.75       941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision decreased, but recall increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67623522893158161"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc = metrics.roc_auc_score(\n",
    "    y_true=y_test,\n",
    "    y_score=y_pred,\n",
    "    average=None\n",
    ")\n",
    "auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45644599303135891"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = metrics.recall_score(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred\n",
    ")\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'AUROC': 0.70899796481582122,\n",
       "  'accuracy': 0.77895855472901165,\n",
       "  'model_name': 'LogReg_Bin',\n",
       "  'recall': 0.52961672473867594},\n",
       " {'AUROC': 0.73227471789789966,\n",
       "  'accuracy': 0.73113708820403822,\n",
       "  'model_name': 'LogReg_Bin_Bal',\n",
       "  'recall': 0.73519163763066198},\n",
       " {'AUROC': 0.74939530522434983,\n",
       "  'accuracy': 0.74814027630180657,\n",
       "  'model_name': 'LogReg_Bin_Bal_GSCV',\n",
       "  'recall': 0.7526132404181185},\n",
       " {'AUROC': 0.73588423957634075,\n",
       "  'accuracy': 0.73751328374070135,\n",
       "  'model_name': 'LogReg_Multi',\n",
       "  'recall': 0.73170731707317072},\n",
       " {'AUROC': 0.51045296167247389,\n",
       "  'accuracy': 0.70138150903294372,\n",
       "  'model_name': 'LogReg_Multi_GSCV',\n",
       "  'recall': 0.020905923344947737},\n",
       " {'AUROC': 0.6635765964474849,\n",
       "  'accuracy': 0.74707757704569611,\n",
       "  'model_name': 'RandForestClass',\n",
       "  'recall': 0.44947735191637633},\n",
       " {'AUROC': 0.67623522893158161,\n",
       "  'accuracy': 0.7619553666312433,\n",
       "  'model_name': 'RandForestClass_Tuned',\n",
       "  'recall': 0.45644599303135891}]"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add_score(model_name,accuracy,AUROC,recall)\n",
    "add_score('RandForestClass_Tuned',acc,auroc,recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field-Aware Factorization Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A description of __[Field-aware Factorization Machines](https://www.csie.ntu.edu.tw/~r01922136/slides/ffm.pdf)__ from the folks who won two Kaggle competitions with the model.\n",
    "\n",
    "And __[here](https://github.com/mglowacki100/libffm-python)__ is a Python wrapper for the FFM library, which was written in C++."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named ffm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-320-244abf364e9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mffm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named ffm"
     ]
    }
   ],
   "source": [
    "import ffm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alas, I couldn't get the library to work. Seems like the error lies in the gcc compiler, which I had to download and upgrade several times. I'm stuck with this error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```g++ -Wall -O3 -std=c++0x -march=native -fopenmp -DUSESSE -DUSEOMP -fPIC -c -o timer.o timer.cpp\n",
    "/var/folders/30/nm2sfklx0_z7972s169n8p900000gn/T//ccVbLqTB.s:73:no such instruction: `vxorps %xmm0, %xmm0,%xmm0'\n",
    "/var/folders/30/nm2sfklx0_z7972s169n8p900000gn/T//ccVbLqTB.s:82:no such instruction: `vcvtsi2ssq %rdx, %xmm0,%xmm0'\n",
    "/var/folders/30/nm2sfklx0_z7972s169n8p900000gn/T//ccVbLqTB.s:85:no such instruction: `vdivss lC0(%rip), %xmm0,%xmm0'\n",
    "/var/folders/30/nm2sfklx0_z7972s169n8p900000gn/T//ccVbLqTB.s:93:no such instruction: `vxorps %xmm0, %xmm0,%xmm0'\n",
    "/var/folders/30/nm2sfklx0_z7972s169n8p900000gn/T//ccVbLqTB.s:94:no such instruction: `vcvtsi2ssq 8(%rdi), %xmm0,%xmm0'\n",
    "/var/folders/30/nm2sfklx0_z7972s169n8p900000gn/T//ccVbLqTB.s:95:no such instruction: `vdivss lC0(%rip), %xmm0,%xmm0'\n",
    "make: *** [timer.o] Error 1```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling & Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'AUROC': 0.70899796481582122,\n",
       "  'accuracy': 0.77895855472901165,\n",
       "  'model_name': 'LogReg_Bin',\n",
       "  'recall': 0.52961672473867594},\n",
       " {'AUROC': 0.73227471789789966,\n",
       "  'accuracy': 0.73113708820403822,\n",
       "  'model_name': 'LogReg_Bin_Bal',\n",
       "  'recall': 0.73519163763066198},\n",
       " {'AUROC': 0.74939530522434983,\n",
       "  'accuracy': 0.74814027630180657,\n",
       "  'model_name': 'LogReg_Bin_Bal_GSCV',\n",
       "  'recall': 0.7526132404181185},\n",
       " {'AUROC': 0.73588423957634075,\n",
       "  'accuracy': 0.73751328374070135,\n",
       "  'model_name': 'LogReg_Multi',\n",
       "  'recall': 0.73170731707317072},\n",
       " {'AUROC': 0.51045296167247389,\n",
       "  'accuracy': 0.70138150903294372,\n",
       "  'model_name': 'LogReg_Multi_GSCV',\n",
       "  'recall': 0.020905923344947737},\n",
       " {'AUROC': 0.6635765964474849,\n",
       "  'accuracy': 0.74707757704569611,\n",
       "  'model_name': 'RandForestClass',\n",
       "  'recall': 0.44947735191637633},\n",
       " {'AUROC': 0.67623522893158161,\n",
       "  'accuracy': 0.7619553666312433,\n",
       "  'model_name': 'RandForestClass_Tuned',\n",
       "  'recall': 0.45644599303135891}]"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708998</td>\n",
       "      <td>0.778959</td>\n",
       "      <td>LogReg_Bin</td>\n",
       "      <td>0.529617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.732275</td>\n",
       "      <td>0.731137</td>\n",
       "      <td>LogReg_Bin_Bal</td>\n",
       "      <td>0.735192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.749395</td>\n",
       "      <td>0.748140</td>\n",
       "      <td>LogReg_Bin_Bal_GSCV</td>\n",
       "      <td>0.752613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.735884</td>\n",
       "      <td>0.737513</td>\n",
       "      <td>LogReg_Multi</td>\n",
       "      <td>0.731707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.510453</td>\n",
       "      <td>0.701382</td>\n",
       "      <td>LogReg_Multi_GSCV</td>\n",
       "      <td>0.020906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.663577</td>\n",
       "      <td>0.747078</td>\n",
       "      <td>RandForestClass</td>\n",
       "      <td>0.449477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.676235</td>\n",
       "      <td>0.761955</td>\n",
       "      <td>RandForestClass_Tuned</td>\n",
       "      <td>0.456446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AUROC  accuracy             model_name    recall\n",
       "0  0.708998  0.778959             LogReg_Bin  0.529617\n",
       "1  0.732275  0.731137         LogReg_Bin_Bal  0.735192\n",
       "2  0.749395  0.748140    LogReg_Bin_Bal_GSCV  0.752613\n",
       "3  0.735884  0.737513           LogReg_Multi  0.731707\n",
       "4  0.510453  0.701382      LogReg_Multi_GSCV  0.020906\n",
       "5  0.663577  0.747078        RandForestClass  0.449477\n",
       "6  0.676235  0.761955  RandForestClass_Tuned  0.456446"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAGRCAYAAADLpq+LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAQq9ha6cP1mDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12efa5f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## h/t Chris Albon again\n",
    "## https://chrisalbon.com/python/matplotlib_grouped_bar_plot.html\n",
    "\n",
    "# Setting the positions and width for the bars\n",
    "pos = list(range(len(df_scores['AUROC']))) \n",
    "width = 0.25 \n",
    "\n",
    "# Plotting the bars\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "# Create a bar with pre_score data,\n",
    "# in position pos,\n",
    "plt.bar(pos, \n",
    "        #using df['pre_score'] data,\n",
    "        df_scores['AUROC'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#EE3224', \n",
    "        # with label the first value in first_name\n",
    "        label=df_scores['model_name'][0]) \n",
    "\n",
    "# Create a bar with mid_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width for p in pos], \n",
    "        #using df['mid_score'] data,\n",
    "        df_scores['accuracy'],\n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#F78F1E', \n",
    "        # with label the second value in first_name\n",
    "        label=df_scores['model_name'][1]) \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width*2 for p in pos], \n",
    "        #using df['post_score'] data,\n",
    "        df_scores['recall'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#FFC222', \n",
    "        # with label the third value in first_name\n",
    "        label=df_scores['model_name'][2]) \n",
    "\n",
    "# Set the y axis label\n",
    "ax.set_ylabel('score')\n",
    "\n",
    "# Set the chart's title\n",
    "ax.set_title('Model Scores')\n",
    "\n",
    "# Set the position of the x ticks\n",
    "ax.set_xticks([p + 1.5 * width for p in pos])\n",
    "\n",
    "# Set the labels for the x ticks\n",
    "ax.set_xticklabels(df_scores['model_name'],rotation = 45, ha=\"right\")\n",
    "\n",
    "# Setting the x-axis and y-axis limits\n",
    "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# Adding the legend and showing the plot\n",
    "plt.legend(['AUROC', 'accuracy', 'recall'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is so pretty. I'm leaving it and copying the code again to do the colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAGRCAYAAADLpq+LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSc38H4TGCoNG6MaZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ed81b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## h/t Chris Albon again\n",
    "## https://chrisalbon.com/python/matplotlib_grouped_bar_plot.html\n",
    "\n",
    "# Setting the positions and width for the bars\n",
    "pos = list(range(len(df_scores['AUROC']))) \n",
    "width = 0.25 \n",
    "\n",
    "# Plotting the bars\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "# Create a bar with pre_score data,\n",
    "# in position pos,\n",
    "plt.bar(pos, \n",
    "        #using df['pre_score'] data,\n",
    "        df_scores['AUROC'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#D3D3D3', \n",
    "        # with label the first value in first_name\n",
    "        label=df_scores['model_name'][0]) \n",
    "\n",
    "# Create a bar with mid_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width for p in pos], \n",
    "        #using df['mid_score'] data,\n",
    "        df_scores['accuracy'],\n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#C0C0C0', \n",
    "        # with label the second value in first_name\n",
    "        label=df_scores['model_name'][1]) \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width*2 for p in pos], \n",
    "        #using df['post_score'] data,\n",
    "        df_scores['recall'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#FFC222', \n",
    "        # with label the third value in first_name\n",
    "        label=df_scores['model_name'][2]) \n",
    "\n",
    "# Set the y axis label\n",
    "ax.set_ylabel('score')\n",
    "\n",
    "# Set the chart's title\n",
    "ax.set_title('Model Scores')\n",
    "\n",
    "# Set the position of the x ticks\n",
    "ax.set_xticks([p + 1.5 * width for p in pos])\n",
    "\n",
    "# Set the labels for the x ticks\n",
    "ax.set_xticklabels(df_scores['model_name'],rotation = 45, ha=\"right\")\n",
    "\n",
    "# Setting the x-axis and y-axis limits\n",
    "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# Adding the legend and showing the plot\n",
    "plt.legend(['AUROC', 'accuracy', 'recall'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the presentation deck."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
